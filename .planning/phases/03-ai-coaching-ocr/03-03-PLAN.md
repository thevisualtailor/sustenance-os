---
phase: 03-ai-coaching-ocr
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - src/chat/sustenance-persona.js
  - src/chat/chat-view.js
  - src/chat/chat-view.css
  - src/chat/message-renderer.js
autonomous: false

must_haves:
  truths:
    - "User can send a text message and receive a coaching response from the Sustenance persona (not the Phase 2 stub)"
    - "User can upload a MacroFactor screenshot and receive a coaching response without any raw numbers appearing in the UI"
    - "Coach refers to trends and patterns, never exact figures — even if asked directly"
    - "When meal data is available, the coach assigns and displays a tier pill (Gold/Silver/Bronze/Showing Up/Off Track)"
    - "Coach asks a contextual follow-up when an eating pattern is detected"
    - "XLSX upload triggers coaching response with tier assignment based on parsed data"
  artifacts:
    - path: "src/chat/sustenance-persona.js"
      provides: "System prompt with BED guardrails, tier logic, coaching voice"
      exports: ["buildSustenancePersonaPrompt"]
    - path: "src/chat/chat-view.js"
      provides: "Full coaching pipeline replacing getStubResponse"
      contains: "sendMessage|sendOcrExtraction"
    - path: "src/chat/message-renderer.js"
      provides: "Tier pill rendering via [TIER:X] token post-processing"
      contains: "TIER:"
    - path: "src/chat/chat-view.css"
      provides: "Tier pill gradient styles for all five tiers"
      contains: "tier-pill"
  key_links:
    - from: "src/chat/chat-view.js"
      to: "src/chat/claude-api.js"
      via: "sendMessage and sendOcrExtraction calls replace getStubResponse"
      pattern: "sendMessage|sendOcrExtraction"
    - from: "src/chat/chat-view.js"
      to: "src/chat/session-context.js"
      via: "setOcrData/setXlsxData after extraction, getContextBlock for persona prompt"
      pattern: "setOcrData|setXlsxData|getContextBlock"
    - from: "src/chat/chat-view.js"
      to: "src/chat/sustenance-persona.js"
      via: "buildSustenancePersonaPrompt called before every sendMessage"
      pattern: "buildSustenancePersonaPrompt"
    - from: "src/chat/message-renderer.js"
      to: "tier pill spans"
      via: "post-process [TIER:X] tokens after marked.parse + DOMPurify"
      pattern: "\\[TIER:[A-Z_]+\\]"
---

<objective>
Wire the complete coaching pipeline: Sustenance persona system prompt, tier pill rendering, and the full message flow replacing the Phase 2 stub with real Claude Haiku calls. This is the plan that makes the AI actually work.

Purpose: This connects all the infrastructure (API client from Plan 01, upload flow from Plan 02) into a working coaching experience. After this plan, the app is a functional AI nutrition coach.
Output: sustenance-persona.js (new), modified chat-view.js (real pipeline), modified message-renderer.js (tier pills), modified chat-view.css (tier pill styles)
</objective>

<execution_context>
@/Users/jaycarter/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jaycarter/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-coaching-ocr/03-CONTEXT.md
@.planning/phases/03-ai-coaching-ocr/03-RESEARCH.md
@.planning/phases/03-ai-coaching-ocr/03-01-SUMMARY.md
@.planning/phases/03-ai-coaching-ocr/03-02-SUMMARY.md
@src/chat/chat-view.js
@src/chat/chat-view.css
@src/chat/message-renderer.js
@src/chat/claude-api.js
@src/chat/session-context.js
@src/chat/upload-modal.js
@src/chat/message-store.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Sustenance persona system prompt + tier pill rendering</name>
  <files>src/chat/sustenance-persona.js, src/chat/message-renderer.js, src/chat/chat-view.css</files>
  <action>
**Step 1: Create `src/chat/sustenance-persona.js`**

Export `buildSustenancePersonaPrompt(sessionContext)`:
- Takes the current session context string (from `getContextBlock()`) and builds the full system prompt
- The system prompt MUST include ALL of the following sections (these are locked decisions from the user):

**Identity:** "You are Sustenance, a warm and grounding nutrition coach — like a wise friend who gets it."

**Voice rules:**
- Warm and grounding. Not clinical, not prescriptive. Calm, never alarmed.
- Use relative framing: "a bit more protein today than yesterday". Comparisons between days are allowed; absolute numbers are not.
- Close most responses with a contextual question — open, curious, or reflective depending on what was just discussed.
- Be encouraging in both directions: celebrate a great day, stay supportive on a difficult one.
- When the user is struggling emotionally, acknowledge that first before any coaching point.

**Hard lines (BED guardrails — NON-NEGOTIABLE):**
- NEVER state or calculate calorie totals, even if asked directly. Acknowledge the question, redirect to patterns. Never state the figure.
- NEVER label foods as good/bad, clean/dirty, or use moral framing around food.
- NEVER comment on body weight or body shape.
- NEVER show raw nutrition numbers (calories, grams) in your response text.

**Tier system instructions:**
When meal data is available (from OCR screenshot or XLS upload), rate each meal using ONE of these markers embedded in the response. Use the marker token format exactly — it will be rendered as a styled pill:
- `[TIER:GOLD]` — 10-25%+ below calorie target for that meal + high protein (>30% of cals from protein) + under fat limit + close to optimal carbs
- `[TIER:SILVER]` — Solid. Pretty damn good. Close to ideal macros. Calorie-appropriate.
- `[TIER:BRONZE]` — ~70% of ideal. Minimum viable. Worth celebrating.
- `[TIER:SHOWING_UP]` — Tracked but below Bronze threshold. The habit is the win. Celebrate consistency.
- `[TIER:OFF_TRACK]` — No tracking data for this meal/time block. Gentle wake-up. Not punishing. "Better to show up than be off track."

Only assign a tier when you have actual data (OCR/XLS). Not from text descriptions alone.
Place the tier marker inline in your response text, e.g., "Your lunch was [TIER:SILVER] — solid across the board."

**Daily arc coaching:**
If data covers multiple meals in a day:
- Reference trajectory mid-day: "You had a Bronze breakfast — shoot for Silver at lunch to finish strong."
- End-of-day summary: summarise per-meal tiers AND provide a day-level summary tier.

**Contextual follow-up behaviour:**
- Default: close most responses with a question contextual to what was just discussed
- Trigger patterns: missed meals detected, user mentions stress/tiredness/mood, user logs a rateable meal, repeated below-Bronze signals
- When a coaching point exists: follow-up about that point
- When no coaching point: "anything else I can help with?" style close

**Philosophy:** "F*ck perfection." Showing up matters most. Progress from Showing Up to Bronze to Silver to Gold over time.

**Session context injection:**
If sessionContext is non-empty, include it in the system prompt under a clearly labeled section: `## Current Session Data (INTERNAL — NOT FOR DISPLAY)` followed by the context string. This data is for the AI to read and coach from — it must NOT be quoted or referenced by number in the response.

**Format instructions:** Respond in Markdown. Keep responses conversational — no unnecessary bullet point lists unless they genuinely help clarity.

**Step 2: Modify `src/chat/message-renderer.js`**

Add tier pill post-processing to the assistant message rendering path:

1. Define a `TIER_CONFIG` object mapping tier keys to labels and CSS classes:
   - `GOLD` -> label "Gold Tier", class "tier-pill tier-pill--gold"
   - `SILVER` -> label "Silver Tier", class "tier-pill tier-pill--silver"
   - `BRONZE` -> label "Bronze Tier", class "tier-pill tier-pill--bronze"
   - `SHOWING_UP` -> label "Showing Up", class "tier-pill tier-pill--showing-up"
   - `OFF_TRACK` -> label "Off Track", class "tier-pill tier-pill--off-track"

2. Create `injectTierPills(html)` function that replaces `[TIER:KEY]` tokens with styled span elements:
   ```
   html.replace(/\[TIER:([A-Z_]+)\]/g, (match, key) => { ... })
   ```

3. In the assistant branch of `renderMessage`, change the rendering pipeline to:
   a. `marked.parse(content)` — markdown to HTML
   b. `injectTierPills(html)` — replace tier tokens with span elements
   c. `DOMPurify.sanitize(html, CLEAN_CONFIG)` — sanitize with tier pill classes allowed

4. Update DOMPurify config to allow tier pill spans:
   ```javascript
   const CLEAN_CONFIG = {
     ALLOWED_TAGS: ['p', 'strong', 'em', 'ul', 'ol', 'li', 'h1', 'h2', 'h3', 'code', 'pre', 'br', 'span', 'a', 'blockquote'],
     ALLOWED_ATTR: ['class', 'href'],
   };
   ```
   Note: DOMPurify's `ALLOWED_CLASSES` is not a standard config option in all versions. Instead, after sanitize, the class attributes on allowed tags will pass through if the tag itself is in ALLOWED_TAGS and 'class' is in ALLOWED_ATTR. This is sufficient.

IMPORTANT: The order is `marked.parse` -> `injectTierPills` -> `DOMPurify.sanitize`. Inject BEFORE sanitize so DOMPurify validates the tier pill HTML. The tier pill spans use only `class` attribute which is in ALLOWED_ATTR.

**Step 3: Add tier pill CSS to `src/chat/chat-view.css`**

Add after the markdown rendering styles section:

```css
/* --- Tier Pills --- */
.tier-pill {
  display: inline-block;
  padding: 2px 10px;
  border-radius: 12px;
  font-size: 12px;
  font-weight: 600;
  font-family: var(--font-body);
  letter-spacing: 0.02em;
  vertical-align: baseline;
  margin: 0 2px;
}

.tier-pill--gold {
  background: linear-gradient(135deg, #b8860b, #ffd700, #b8860b);
  color: #1a1a1a;
}

.tier-pill--silver {
  background: linear-gradient(135deg, #808080, #c0c0c0, #808080);
  color: #1a1a1a;
}

.tier-pill--bronze {
  background: linear-gradient(135deg, #8b4513, #cd7f32, #8b4513);
  color: #fff;
}

.tier-pill--showing-up {
  background: linear-gradient(135deg, #2d5a27, #4caf50, #2d5a27);
  color: #fff;
}

.tier-pill--off-track {
  background: linear-gradient(135deg, #8b6914, #f5a623, #8b6914);
  color: #1a1a1a;
}
```

These are subtle gradient pills per the locked decision: "displayed as a subtle gradient pill/dot embedded in coaching responses."
  </action>
  <verify>
Run `npm run build` — no errors. Manually test tier pill rendering by temporarily adding a test message with `[TIER:GOLD]` content via the browser console or by modifying the stub response to include tier markers. Verify the pill renders as a styled span, not as literal text `[TIER:GOLD]`.
  </verify>
  <done>
sustenance-persona.js exports buildSustenancePersonaPrompt with all BED guardrails, tier instructions, voice rules, and contextual follow-up behavior. message-renderer.js post-processes [TIER:X] tokens into styled gradient pills. Five tier pill CSS classes render with correct gradient colors. Build succeeds.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire the coaching pipeline — replace stub with real Claude API</name>
  <files>src/chat/chat-view.js</files>
  <action>
This is the critical wiring task. Rewrite the `handleSend` flow in `chat-view.js` to replace `getStubResponse()` with the real Claude coaching pipeline.

**Step 1: Update imports**

Remove: `import { createMessageStore, getStubResponse } from './message-store.js'`
Replace with:
```javascript
import { createMessageStore, createImageAttachment, createXlsxAttachment } from './message-store.js';
import { sendMessage, sendOcrExtraction, fileToBase64 } from './claude-api.js';
import { buildSustenancePersonaPrompt } from './sustenance-persona.js';
import { setOcrData, setXlsxData, getContextBlock, clearSession } from './session-context.js';
```

**Step 2: Add conversation history array**

Add a module-level `conversationHistory = []` array that tracks messages in the format the Anthropic API expects: `[{ role: 'user'|'assistant', content: string|array }]`.

This is separate from the message store (which is for UI rendering). The conversation history is what gets sent to the API.

**Step 3: Rewrite handleSend for three message types**

The new `handleSend` must handle three cases:

**Case A: Text-only message (no attachment)**
1. Get text from textarea, clear input
2. Add user message to store: `store.addMessage('user', text)`
3. Add to conversationHistory: `{ role: 'user', content: text }`
4. Render user message in thread, fade empty state
5. Show thinking indicator
6. Build system prompt: `buildSustenancePersonaPrompt(getContextBlock())`
7. Call `sendMessage({ systemPrompt, messages: conversationHistory })`
8. Remove thinking indicator
9. Add assistant message to store + render
10. Add to conversationHistory: `{ role: 'assistant', content: responseText }`

**Case B: Image attachment (screenshot)**
This uses the TWO-CALL pipeline (per research recommendation — safest for BED guardrails):

1. Get text (or "Analyse this" default), clear input
2. Convert image to base64: `const base64 = await fileToBase64(attachment.file)`
3. Add user message to store WITH attachment: `store.addMessage('user', text, createImageAttachment(attachment.file))` — note: createImageAttachment was already called in the upload flow from Plan 02, so the attachment already has the blob URL. But we need the File reference for base64 conversion.
4. Render user message (thumbnail visible in bubble)
5. Show thinking indicator

**OCR extraction call (hidden — result never rendered):**
6. Call `sendOcrExtraction({ base64, mediaType: attachment.file.type })` — this returns parsed JSON
7. Store in session context: `setOcrData(extractedData)`

**Replace image in conversation history:**
8. Add to conversationHistory: `{ role: 'user', content: text + '\n[Image analysed — data stored in session context]' }` — NOT the actual image content blocks. The image was used for OCR only; subsequent turns send text context instead. This prevents the image being re-sent every turn (cost pitfall from research).

**Coaching response call:**
9. Build system prompt: `buildSustenancePersonaPrompt(getContextBlock())` — now includes OCR data
10. Call `sendMessage({ systemPrompt, messages: conversationHistory })`
11. Remove thinking indicator
12. Add assistant message to store + render
13. Add to conversationHistory: `{ role: 'assistant', content: responseText }`

**Case C: XLSX attachment**
1. Get text (or "Analyse this" default), clear input
2. The XLSX data was already parsed by `createXlsxAttachment` in Plan 02 — the attachment object has `{ type: 'xlsx', filename, data: { dailyRows, foodRows } }`
3. Add user message to store WITH attachment: `store.addMessage('user', text, attachment)`
4. Render user message (file badge visible in bubble)
5. Show thinking indicator
6. Store in session context: `setXlsxData(attachment.data)` — the parsed dailyRows/foodRows
7. Add to conversationHistory: `{ role: 'user', content: text + '\n[XLSX file uploaded: ' + attachment.filename + ' — data stored in session context]' }`
8. Build system prompt with context, call sendMessage, render response (same as Case A steps 6-10)

**Step 4: Update the "New Conversation" reset**

In the existing new-conversation button click handler, also:
- Clear `conversationHistory = []`
- Call `clearSession()` to reset OCR/XLSX data

**Step 5: Error handling**

Wrap each API call in try/catch:
- If `sendOcrExtraction` fails: show an error message in the thread as an assistant message with text "I had trouble reading that image. Could you try uploading it again?" Remove thinking indicator. Do NOT throw — the conversation continues.
- If `sendMessage` fails: show error message "Something went wrong — please check your API key and try again." Include the error message from the API if available for debugging. Remove thinking indicator.
- Always set `isThinking = false` in a finally block.

**Step 6: Decide how pendingAttachment flows**

From Plan 02, the upload modal callbacks set a `pendingAttachment` and call `handleSendWithAttachment()`. Refactor this:
- Remove the separate `handleSendWithAttachment` if it exists
- Instead, the upload callbacks should set `pendingAttachment` and call `handleSend()` directly
- `handleSend` checks `pendingAttachment` at the start to determine which case (A, B, or C) to execute
- After processing, set `pendingAttachment = null`

If Plan 02 implemented `handleSendWithAttachment` as a separate function, merge its logic into the unified `handleSend`.
  </action>
  <verify>
Run `npm run build` — no errors, no reference to `getStubResponse`. Run `npm run dev`:

1. Text message test: Type "Hello" and send. Should get a real Claude Haiku response (not the Phase 2 stub). The response should use the Sustenance persona voice.
2. Error test: Clear localStorage API key, reload, enter a bad key. Send a message — should show error message in thread.
3. Image test: Tap +, select Photos, choose any image. Should send immediately with "Analyse this", show thinking indicator, then show coaching response with tier pill if nutrition data was extracted.
4. New conversation: Tap compose button — thread clears, session context resets.

Check browser console for any CORS errors or API errors.
  </verify>
  <done>
getStubResponse is fully replaced. Text messages get real Claude coaching responses. Image uploads trigger two-call OCR pipeline (extraction hidden, coaching rendered). XLSX uploads inject parsed data into session context. Tier pills render in coaching responses. Conversation history tracks correctly. New conversation resets everything. Error messages show gracefully on API failures.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete AI coaching pipeline: Sustenance persona with BED guardrails, screenshot OCR via Claude Vision (two-call pipeline), XLSX parsing via SheetJS, tier pill rendering (Gold/Silver/Bronze/Showing Up/Off Track), contextual follow-up questions, and the full upload flow (+ button, Camera/Photos/Files modal).
  </what-built>
  <how-to-verify>
Test on iPhone (primary device) via the Vercel production URL after pushing to main:

1. **API key setup:** First load should show API key overlay. Enter your Anthropic API key and tap Continue.

2. **Text chat:** Send "Hey, how should I think about my meals today?" — verify the response uses the Sustenance persona voice (warm, grounding, no numbers, ends with a question).

3. **BED guardrail test:** Ask "How many calories did I eat yesterday?" — verify the coach deflects and reframes WITHOUT stating any number.

4. **Screenshot upload:** Tap +, select Photos, choose a MacroFactor screenshot. Verify:
   - Image sends immediately with "Analyse this"
   - Thumbnail appears in your message bubble (iMessage-style)
   - Coach responds with trend-based feedback (no raw numbers in the response)
   - A tier pill appears in the response (gradient pill, not raw text)

5. **XLSX upload:** Tap +, select Files, choose a MacroFactor .xlsx export. Verify:
   - File badge appears in your message bubble
   - Coach responds with tier-rated feedback referencing meal patterns

6. **Tier pill visual:** Check that tier pills are subtle gradient pills embedded in the response text — Gold (gold gradient), Silver (silver gradient), Bronze (bronze gradient), Showing Up (green gradient), Off Track (amber gradient).

7. **Contextual follow-up:** After a few messages, verify the coach closes responses with relevant questions.

8. **New conversation:** Tap the compose button (top-right) — verify thread clears and a fresh conversation starts.

9. **Camera test (if available):** Tap + and select Camera — verify it opens the device camera.
  </how-to-verify>
  <resume-signal>Type "approved" if all checks pass, or describe any issues to fix.</resume-signal>
</task>

</tasks>

<verification>
- `npm run build` succeeds with no reference to `getStubResponse`
- No raw nutrition numbers (calories, grams) appear anywhere in the chat thread
- Coach voice matches locked decisions: warm, relative framing, contextual questions
- BED guardrails hold: calorie questions deflected, no moral food framing, no body comments
- Tier pills render as styled gradient spans (not raw `[TIER:X]` text)
- Two-call OCR pipeline: image used for extraction only, not re-sent in subsequent turns
- XLSX parsing reads both 'Quick Export' and 'Food Log' sheets correctly
- Session context resets on new conversation
- Error handling shows user-friendly messages on API failures
</verification>

<success_criteria>
Phase 3 is functionally complete: the Sustenance persona is live, screenshots and XLSX exports are processed silently, coaching responses are BED-safe with tier pills, and contextual follow-ups are generated. All requirements (OCR-01, OCR-02, OCR-03, COACH-01, COACH-02, COACH-03, COACH-04) are satisfied. Ready for iPhone verification.
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-coaching-ocr/03-03-SUMMARY.md`
</output>
